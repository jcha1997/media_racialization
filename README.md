# Media Racialization

Jeremiah Cha

## Background

In this article, I propose the use of word vectorization methods to operationalize the concept of issue racialization in the media.
Despite a rich theoretical scholarship dedicated to its process, strategies to measure issue racialization in media remain limited.
Many boil down to “knowing it when you see it,” leaving detection of a racialized issue to subjective human coding. For instance, existing 
approaches rely on manual coding of a set of texts in a corpus with machine learning approaches projecting these to additional observations 
based on a training set. Although a useful tool, the binary nature of this coding makes comparability difficult across not only
policy areas, but also time. Standard coding schemes generally cannot distinguish the extent to which different policies are 
themselves racialized, particularly making comparison between issues with clear-cut racial content and those without such provisions impossible.
Additionally, while coders may agree on whether a policy is racialized, these judgements reflect the nature of racialization at the time
of coding, which may drastically change given exogenous shocks to any policy area. While these approaches make use of emerging natural 
language processing (NLP) methodologies, they remain limited in their precision and application.

## Code

All code is done through Jupyter Notebooks through the ProQuest TDM remote computing environments. 
